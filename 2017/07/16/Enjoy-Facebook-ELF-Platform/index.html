<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Enjoy Facebook ELF Platform | Gao Fangshu</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Facebook 在7月6日开源了 ELF(Extensive, Lightweight and Flexible) 平台，ELF 对即时战略游戏模拟做了很多优化，其轻量级的 MiniRTS 模拟环境使开发增强学习算法变得更高效，更多介绍可以参考 GitHub 的 README (Documentation 还在每天更新，目前虽然内容不多，但可持续关注)，另外还有 Facebook 主页介绍 和">
<meta property="og:type" content="article">
<meta property="og:title" content="Enjoy Facebook ELF Platform">
<meta property="og:url" content="http://gaofangshu.com/blog/2017/07/16/Enjoy-Facebook-ELF-Platform/index.html">
<meta property="og:site_name" content="Gao Fangshu">
<meta property="og:description" content="Facebook 在7月6日开源了 ELF(Extensive, Lightweight and Flexible) 平台，ELF 对即时战略游戏模拟做了很多优化，其轻量级的 MiniRTS 模拟环境使开发增强学习算法变得更高效，更多介绍可以参考 GitHub 的 README (Documentation 还在每天更新，目前虽然内容不多，但可持续关注)，另外还有 Facebook 主页介绍 和">
<meta property="og:image" content="http://gaofangshu.com/blog/gaofangshu.com/blog/img/evaluate.png">
<meta property="og:image" content="http://gaofangshu.com/blog/gaofangshu.com/blog/img/valuation.gif">
<meta property="og:updated_time" content="2017-07-15T22:51:16.064Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Enjoy Facebook ELF Platform">
<meta name="twitter:description" content="Facebook 在7月6日开源了 ELF(Extensive, Lightweight and Flexible) 平台，ELF 对即时战略游戏模拟做了很多优化，其轻量级的 MiniRTS 模拟环境使开发增强学习算法变得更高效，更多介绍可以参考 GitHub 的 README (Documentation 还在每天更新，目前虽然内容不多，但可持续关注)，另外还有 Facebook 主页介绍 和">
<meta name="twitter:image" content="http://gaofangshu.com/blog/gaofangshu.com/blog/img/evaluate.png">
  
  
    <link rel="icon" href="favicon.ico">
  
  <link href="//fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">Gao Fangshu</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/blog/" id="subtitle">It is our choices that show what we truly are.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-home-icon" class="nav-icon" href="/blog/"></a>
        
          <a id="nav-tags-icon" class="nav-icon" href="/blog/tags"></a>
        
          <a id="nav-archives-icon" class="nav-icon" href="/blog/archives"></a>
        
          <a id="nav-about-icon" class="nav-icon" href="/blog/about"></a>
        
        
      </nav>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Enjoy-Facebook-ELF-Platform" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Enjoy Facebook ELF Platform
    </h1>
  

      </header>
    
    <time class="article-date" datetime="2017-07-15T22:32:00.000Z" itemprop="datePublished">07-16-2017</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>Facebook 在7月6日开源了 ELF(Extensive, Lightweight and Flexible) 平台，ELF 对即时战略游戏模拟做了很多优化，其轻量级的 MiniRTS 模拟环境使开发增强学习算法变得更高效，更多介绍可以参考 GitHub 的 <a href="https://github.com/facebookresearch/ELF/blob/master/README.md" target="_blank" rel="external">README</a> (<a href="http://yuandong-tian.com/html_elf/#" target="_blank" rel="external">Documentation</a> 还在每天更新，目前虽然内容不多，但可持续关注)，另外还有 <a href="https://code.facebook.com/posts/132985767285406/introducing-elf-an-extensive-lightweight-and-flexible-platform-for-game-research/" target="_blank" rel="external">Facebook 主页介绍</a> 和 <a href="https://arxiv.org/abs/1707.01067" target="_blank" rel="external">arXiv paper</a> 可以阅读。<br><a id="more"></a></p>
<p>接下来将从配置环境、用 ELF 自带算法玩 MiniRTS 两个方面展开。</p>
<h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p>由于 ELF 自带的增强学习代码基于只能在 Linux 和 macOS 运行的 <a href="http://pytorch.org/" target="_blank" rel="external">PyTorch</a>，所以本文采用 Ubuntu 16.04 LTS + Anaconda3 4.2.0 + PyTorch 的组合。</p>
<p>在配置 ELF 环境的过程中，还有许多细节 (坑) 需要注意：</p>
<ul>
<li><p>需要安装编译 C++ 的 Linux 库，比如 gcc(&gt;=4.9)，在 Linux 终端中运行：</p>
<figure class="highlight actionscript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-<span class="keyword">get</span> install gcc</div></pre></td></tr></table></figure>
</li>
<li><p>需要安装 tbb 库，否则程序会报错，具体见 <a href="https://github.com/facebookresearch/ELF/issues/7" target="_blank" rel="external">Issue</a>，在 Linux 终端中运行：</p>
<figure class="highlight q"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-<span class="built_in">get</span> install libtbb-<span class="built_in">dev</span></div></pre></td></tr></table></figure>
</li>
<li><p>在可视化游戏界面的时候，需要用于前后端连接的库 zeromq 4.0.4 和 libczmq 3.0.2，因为没有比较细致的安装文档，摸索了比较久，有以下链接值得参考：</p>
<ul>
<li><a href="https://zeromq.github.io/zeromq4-1/" target="_blank" rel="external">Older 4.x ZeroMQ downloads</a></li>
<li><a href="https://tuananh.org/2015/06/16/how-to-install-zeromq-on-ubuntu/" target="_blank" rel="external">How to install ZeroMQ on Ubuntu</a></li>
<li><a href="https://stackoverflow.com/questions/41289619/how-to-install-zeromq-4-on-ubuntu-16-10-from-source" target="_blank" rel="external">How to install ZeroMQ 4 on Ubuntu 16.10 from source</a></li>
<li><a href="http://blog.csdn.net/qq_15437667/article/details/50752399" target="_blank" rel="external">Install ZeroMQ - CSDN</a></li>
<li><a href="http://zeromq.org/area:download" target="_blank" rel="external">libzmq download documentation</a></li>
<li><a href="http://czmq.zeromq.org/page:get-the-software" target="_blank" rel="external">CZMQ documentation</a></li>
<li><a href="http://blog.csdn.net/changqing5818/article/details/46916293" target="_blank" rel="external">Install CZMQ - CSDN</a></li>
</ul>
</li>
<li>安装 python-dev 库，对于Python 2 和 Python 3 分别在 Linux 终端输入：<figure class="highlight q"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-<span class="built_in">get</span> install python-<span class="built_in">dev</span></div><div class="line">sudo apt-<span class="built_in">get</span> install python3-<span class="built_in">dev</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>其他机器配置 ELF 也许会出现不一样的问题，首先看看 ELF 项目的 <a href="https://github.com/facebookresearch/ELF/issues" target="_blank" rel="external">Issues</a> 中有没有人报告相同问题，然后就是各种 Google。严格按照 ELF README.md 中的步骤和库的版本配置，可以降低报错的概率。</p>
<h2 id="用-ELF-玩-MiniRTS"><a href="#用-ELF-玩-MiniRTS" class="headerlink" title="用 ELF 玩 MiniRTS"></a>用 ELF 玩 MiniRTS</h2><p>要用 ELF 玩 MiniRTS，首先需要编译 MiniRTS，即在命令行输入：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">cd</span> ./rts/game_MC</div><div class="line"><span class="keyword">make</span> gen</div><div class="line"><span class="keyword">make</span></div></pre></td></tr></table></figure></p>
<p>生成 <code>minirts.so</code> 供其他 Python 程序调用。注意所有的编译都需要用相同版本的 Python，否则会报错。指定方法例如：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PYTHON_CONFIG=<span class="regexp">/media/g</span>aofangshu<span class="regexp">/Windows/</span>Ubuntu<span class="regexp">/anaconda3/</span>bin<span class="regexp">/python3.5-config make</span></div></pre></td></tr></table></figure></p>
<h3 id="如何开始训练"><a href="#如何开始训练" class="headerlink" title="如何开始训练"></a>如何开始训练</h3><p>训练模型的入口位于 <code>run.py</code>, ELF 平台默认的训练方式是基于命令行的，以本文环境为例，用 Actor-Critic 算法开始训练则在命令行输入：<br><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment">game=</span><span class="string">.</span><span class="comment">/rts/game_MC/game</span> <span class="comment">model=actor_critic</span> <span class="comment">model_file=</span><span class="string">.</span><span class="comment">/rts/game_MC/model</span> <span class="comment">python3</span><span class="string">.</span><span class="comment">5</span> <span class="comment">run</span><span class="string">.</span><span class="comment">py</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">num_games</span> <span class="comment">1024</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">batchsize</span> <span class="comment">128</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">freq_update</span> <span class="comment">50</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">fs_opponent</span> <span class="comment">20</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">latest_start</span> <span class="comment">500</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">latest_start_decay</span> <span class="comment">0</span><span class="string">.</span><span class="comment">99</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">opponent_type</span> <span class="comment">AI_SIMPLE</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">tqdm</span></div></pre></td></tr></table></figure></p>
<p>以上指令定义了游戏环境文件 <code>game=./rts/game_MC/game</code>，模型 <code>model=actor_critic</code> 以及模型所在文件 <code>model_file=./rts/game_MC/model</code>。之后含有 <code>--</code> 的指令则定义了各种参数，比如 <code>--num_games 1024</code> 定义并行运行的游戏数量为 1024；<code>--batchsize 128</code> 定义每批样本大小为 128；<code>--freq_update 50</code> 即训练 agent 的动作输入频率为 50；<code>--fs_opponent 20</code> 即对练的 AI 动作更新频率为 20；相比之下 AI 动作更新更快，这给了 AI 一定的反应优势；<code>--latest_start 500</code> 设定了 agent 开始训练的最晚帧数，随机延迟训练起始帧数是为了使 agent 学习到的开局更多样化，有利于探索各种策略；<code>--latest_start_decay 0.99</code> 则使每局的训练起始帧数随着学习进程逐步下降，原理类似于 ε-greedy 中随机探索概率的逐步下降，兼顾了探索与经验应用；<code>--opponent_type AI_SIMPLE</code> 选择了对手 AI 的类型；<code>--tqdm</code> 则是为了显示训练进度条。除此之外，还有其他训练选项可以定义，具体见对应的 <a href="https://github.com/facebookresearch/ELF/blob/a784175c6fa3ba587d2bb0d0b0311ce64f250e06/docs/source/utils.rst" target="_blank" rel="external">Utils Documentation</a>。</p>
<p>另外，也可以在各种 IDE 中通过运行 <code>run.py</code> 的代码来开始训练模型，这种方法优点在于便于 debug，但缺点是麻烦，需要在代码中修改各种参数的定义，不如命令行直接。</p>
<h3 id="如何继续训练"><a href="#如何继续训练" class="headerlink" title="如何继续训练"></a>如何继续训练</h3><p>在上面的训练过程进行时，ELF 会默认在每 5000 次迭代 (iteration) 后保存一次模型参数到 <code>.bin</code> 文件，如果要在之前的 <code>.bin</code> 文件基础上继续学习，则在训练的指令行后设定 <code>--load</code> 参数，比如，如果要基于 <code>save-62544.bin</code> 继续训练，则输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">game=./rts/game_MC/game model=actor_critic model_file=./rts/game_MC/model python3.5 run.py --num_games 1024 --batchsize 128 --freq_update 50 --fs_opponent 20 --latest_start 500 --latest_start_decay 0.99 --opponent_type AI_SIMPLE --tqdm --load save-62544.bin</div></pre></td></tr></table></figure></p>
<p>将会在终端中看到如下信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Namespace(T=<span class="number">6</span>, actor_only=<span class="keyword">False</span>, ai_type=<span class="string">'AI_NN'</span>, batchsize=<span class="number">128</span>, discount=<span class="number">0.99</span>, entropy_ratio=<span class="number">0.01</span>, epsilon=<span class="number">0.0</span>, eval=<span class="keyword">False</span>, freq_update=<span class="number">50</span>, fs_ai=<span class="number">50</span>, fs_opponent=<span class="number">20</span>, game_multi=<span class="keyword">None</span>, gpu=<span class="keyword">None</span>, grad_clip_norm=<span class="keyword">None</span>, greedy=<span class="keyword">False</span>, handicap_level=<span class="number">0</span>, latest_start=<span class="number">500</span>, latest_start_decay=<span class="number">0.99</span>, load=<span class="string">'save-62544.bin'</span>, max_tick=<span class="number">30000</span>, mcts_threads=<span class="number">64</span>, min_prob=<span class="number">1e-06</span>, num_episode=<span class="number">10000</span>, num_games=<span class="number">1024</span>, num_minibatch=<span class="number">5000</span>, opponent_type=<span class="string">'AI_SIMPLE'</span>, ratio_change=<span class="number">0</span>, record_dir=<span class="string">'./record'</span>, sample_node=<span class="string">'pi'</span>, sample_policy=<span class="string">'epsilon-greedy'</span>, save_dir=<span class="keyword">None</span>, save_prefix=<span class="string">'save'</span>, seed=<span class="number">0</span>, simple_ratio=<span class="number">-1</span>, tqdm=<span class="keyword">True</span>, verbose_collector=<span class="keyword">False</span>, verbose_comm=<span class="keyword">False</span>, wait_per_group=<span class="keyword">False</span>)</div><div class="line">Version:  f25f500a1422b657369d8d8b8c5725d5d74616d7_</div><div class="line">Num Actions:  <span class="number">9</span></div><div class="line">Num unittype:  <span class="number">6</span></div><div class="line">Load <span class="keyword">from</span> save<span class="number">-62544.</span>bin</div><div class="line"><span class="number">79</span>%|██████████████████████████████▋        | <span class="number">3941</span>/<span class="number">5000</span> [<span class="number">04</span>:<span class="number">16</span>&lt;<span class="number">01</span>:<span class="number">29</span>, <span class="number">11.82</span>it/s]</div></pre></td></tr></table></figure></p>
<h3 id="如何评估模型"><a href="#如何评估模型" class="headerlink" title="如何评估模型"></a>如何评估模型</h3><p>评估模型即用训练好的模型与 AI 对抗，并计算打败 AI 的几率，这同样可以在终端中用命令行完成：<br><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment">eval_only=1</span> <span class="comment">game=</span><span class="string">.</span><span class="comment">/rts/game_MC/game</span> <span class="comment">model=actor_critic</span> <span class="comment">model_file=</span><span class="string">.</span><span class="comment">/rts/game_MC/model</span> <span class="comment">python3</span> <span class="comment">run</span><span class="string">.</span><span class="comment">py</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">batchsize</span> <span class="comment">128</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">fs_opponent</span> <span class="comment">20</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">latest_start</span> <span class="comment">500</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">latest_start_decay</span> <span class="comment">0</span><span class="string">.</span><span class="comment">99</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">num_games</span> <span class="comment">1024</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">opponent_type</span> <span class="comment">AI_SIMPLE</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">stats</span> <span class="comment">winrate</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">num_eval</span> <span class="comment">100</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">tqdm</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">load</span> <span class="comment">save</span><span class="literal">-</span><span class="comment">62544</span><span class="string">.</span><span class="comment">bin</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">eval_gpu</span> <span class="comment">0</span></div></pre></td></tr></table></figure></p>
<p><code>eval_only=1</code> 即开启评估模式，<code>--num_eval 100</code> 定义了测试局数为 1000，其他参数与训练时基本一致。但要注意，对于只有 1 个 GPU 的设备，还需要设定评估时的 GPU 个数，即 <code>--eval_gpu 0</code>，因为 ELF 中默认评估模式是多 GPU 设备的。</p>
<p>评估结果显示如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">Load</span> <span class="keyword">from</span> <span class="keyword">save</span><span class="number">-63362.</span><span class="keyword">bin</span></div><div class="line"><span class="keyword">Version</span>:  f25f500a1422b657369d8d8b8c5725d5d74616d7_</div><div class="line"><span class="keyword">Num</span> Actions:  <span class="number">9</span></div><div class="line"><span class="keyword">Num</span> unittype:  <span class="number">6</span></div><div class="line"><span class="number">1003</span>it [<span class="number">00</span>:<span class="number">32</span>, <span class="number">32.09</span>it/s]</div><div class="line">str_win_rate: [<span class="number">0</span>] Win rate: <span class="number">0.336</span> [<span class="number">341</span>/<span class="number">673</span>/<span class="number">1014</span>], Best win rate: <span class="number">0.336</span> [<span class="number">0</span>]</div><div class="line">str_acc_win_rate: Accumulated win rate: <span class="number">0.336</span> [<span class="number">341</span>/<span class="number">673</span>/<span class="number">1014</span>]</div><div class="line"><span class="keyword">count</span>: <span class="number">0</span></div><div class="line">new_record: <span class="literal">True</span></div><div class="line">best_win_rate: <span class="number">0.33629191321495694</span></div><div class="line"><span class="keyword">Beginning</span> <span class="keyword">stop</span> all collectors ...</div><div class="line"><span class="keyword">Stop</span> all game threads ...</div><div class="line"><span class="keyword">Beginning</span> <span class="keyword">stop</span> all collectors ...</div><div class="line"><span class="keyword">Stop</span> all game threads ...</div></pre></td></tr></table></figure></p>
<p>即 <code>save-63362.bin</code> 模型对 AI 的胜率大致为 33.6%，如果手动对整个训练过程进行记录，可以得到如下胜率变化图：<br><img src="gaofangshu.com/blog/img/evaluate.png" width="80%" style="border-radius: 5px"></p>
<h3 id="游戏可视化"><a href="#游戏可视化" class="headerlink" title="游戏可视化"></a>游戏可视化</h3><p>ELF 自带游戏可视化模块，以 MiniRTS 为例，基于之前生成的 <code>minirts.so</code>，进入 <code>backend</code> 文件夹：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">cd</span> ./rts/backend</div><div class="line"><span class="keyword">make</span> minirts GAME_DIR=../game_MC</div></pre></td></tr></table></figure></p>
<p>编译完成后生成 <code>minirts</code> 可执行文件，对它施加命令就可以开始可视化了：<br><figure class="highlight armasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">cd</span> ./rts/<span class="keyword">backend</span></div><div class="line">./minirts <span class="keyword">selfplay </span>--vis_after <span class="number">0</span></div></pre></td></tr></table></figure></p>
<p>打开 <code>./rts/frontend/minirts.html</code> 就可以看到：<br><img src="gaofangshu.com/blog/img/valuation.gif" width="80%" style="border-radius: 5px"><br>这项功能仍有一些 bug，比如 Pause 键暂停后无法继续游戏等等。</p>
<h3 id="平台缺陷"><a href="#平台缺陷" class="headerlink" title="平台缺陷"></a>平台缺陷</h3><p>由于 ELF 开源距今只有 10 天，目前不可避免地有缺陷：</p>
<ul>
<li>源代码中仍然有 bug 需要自己调试或者提交 Issues 给开发者</li>
<li>对于自定义算法还没有接口，仍需要到 <code>./rlpytorch/rlmethod_common.py</code>, <code>./rts/game_MC/model.py</code> 等源文件中添加新的类修改代码，但 Facebook 团队回复 Issues 说之后会将模型调整为独立的包并完善接口</li>
<li>可视化界面目前只能用于人和自带 AI 的对战 (humanplay) 以及自带 AI 之间的对战 (selfplay)，目前没有对于训练模型的可视化，即无法基于 <code>.bin</code> 文件可视化游戏</li>
<li><a href="http://yuandong-tian.com/html_elf/#" target="_blank" rel="external">Documentation</a> 很不健全，还在每天上传完善</li>
</ul>
<p>总之，ELF 会是高效便捷的强化学习研究环境，但目前处于起步阶段，还需要对各个功能的更新持续关注 :D 。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://gaofangshu.com/blog/blog/2017/07/16/Enjoy-Facebook-ELF-Platform/" data-id="cj55vzv450004icvgg7nzp5v0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Machine-Learning/">Machine Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Python/">Python</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/blog/2017/07/09/Linked-List-and-Chained-Assignment/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Linked List and Chained Assignment</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      Powered by <a href="http://hexo.io" target="_blank" title="Hexo">Hexo</a><br>
      ♡ <a href="http://xushuangblog.com/" target="_blank" title="Xu Shuang">Xu Shuang</a><br>
      &copy; 2016-2017 <a href="http://gaofangshu.com/blog/about/" target="_blank" title="Gao Fangshu">Gao Fangshu</a>
      <br>
    </div>
  </div>
</footer>
    </div>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css">
  <script src="/blog/fancybox/jquery.fancybox.pack.js"></script>


<script src="/blog/js/script.js"></script>

<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  // ################### ADDED ON 2017.04.12 BY GAOFANGSHU ###################
  MathJax.Hub.Config({
    CommonHTML: {matchFontHeight: false},
    "HTML-CSS": {matchFontHeight: false},
    SVG: {matchFontHeight: false}
  // #########################################################################
  });
</script>

<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>